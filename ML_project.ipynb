{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "36vtHfYEpPM3"
      },
      "source": [
        "AUTHORS: Ludwig Widesk√§r (luai18@student.bth.se), Akshaya Bathula (akba21@student.bth.se)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-l3PM-3RpVKt"
      },
      "source": [
        "---\n",
        "Import libraries:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kn_MStwymU3s"
      },
      "outputs": [],
      "source": [
        "## Import and install libraries:\n",
        "\n",
        "!python --version\n",
        "!pip install scikit-posthocs\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import time\n",
        "\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import precision_recall_fscore_support\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
        "\n",
        "from tabulate import tabulate\n",
        "\n",
        "from scipy.stats import friedmanchisquare\n",
        "from scikit_posthocs import posthoc_nemenyi_friedman"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yJvYR0NopdgP"
      },
      "outputs": [],
      "source": [
        "## Import train and test datasets (~ 80:20 split of entries).\n",
        "# Also sets headers from first row of dataframe.\n",
        "# Make sure the database can be read before executing.\n",
        "\n",
        "df_train = pd.read_csv(\"/content/sign_mnist_train.csv\", header=[0])\n",
        "df_test = pd.read_csv(\"/content/sign_mnist_test.csv\", header=[0])\n",
        "\n",
        "# ---\n",
        "# Concatenating (without duplicates) and resplit datasets due to fear of overfitting\n",
        "#https://www.kaggle.com/datasets/datamunge/sign-language-mnist/discussion/379925\n",
        "\n",
        "df_all = pd.concat([df_train, df_test], ignore_index=True).drop_duplicates()\n",
        "\n",
        "# Determine X_train, y_train, X_test, and y_test\n",
        "# Use all columns except for the first one as X (only use the pixel values)\n",
        "df_X = df_all.iloc[:,1:]\n",
        "\n",
        "# Use only the first column as y (label, ie. sign language letter\n",
        "# represented as a number (0-25, 9 and 25 is skipped).\n",
        "df_y = df_all.iloc[:,0]\n",
        "\n",
        "# ---\n",
        "# Perform train test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(df_X, df_y, test_size=0.2, random_state=42, stratify=df_y)\n",
        "\n",
        "# ---\n",
        "# Reset index\n",
        "X_train = X_train.reset_index(drop=True)\n",
        "X_test = X_test.reset_index(drop=True)\n",
        "y_train = y_train.reset_index(drop=True)\n",
        "y_test = y_test.reset_index(drop=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## Public variables\n",
        "CR_LETTERS = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'K', 'L', 'M',\n",
        "              'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y']"
      ],
      "metadata": {
        "id": "mrJ1Z86_h8NM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tNHf_wfbsMYf"
      },
      "outputs": [],
      "source": [
        "## Visualize some of the entries\n",
        "number_of_entries_show = 3\n",
        "for i in range(0, number_of_entries_show):\n",
        "  img = X_train.iloc[i].to_numpy()\n",
        "  img = img.reshape((28,28))\n",
        "  plt.imshow(img, cmap='gray')\n",
        "  plt.title(f\"{y_train[i]} : {chr(ord('@') + y_train[i] + 1)}\")\n",
        "  plt.axis(\"off\")\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def render_confusion_matrix(y_true, y_pred):\n",
        "  # Compute the confusion matrix\n",
        "  confusion_mtx = confusion_matrix(y_true, y_pred) \n",
        "\n",
        "  # ---\n",
        "  # Plot the confusion matrix\n",
        "  f, ax = plt.subplots(figsize=(16, 16))\n",
        "  \n",
        "  sns.heatmap(confusion_mtx, annot=True, linewidths=0.01, cmap=\"Greens\",\n",
        "              linecolor=\"gray\", fmt= '.1f', ax=ax)\n",
        "\n",
        "  plt.xlabel(\"Predicted Label\")\n",
        "  plt.ylabel(\"True Label\")\n",
        "\n",
        "  # ---\n",
        "  # Set ticks on axis to letters instead of numbers\n",
        "  for axis in [ax.xaxis, ax.yaxis]:\n",
        "      axis.set(ticks=np.arange(0.5, len(CR_LETTERS)), ticklabels=CR_LETTERS)\n",
        "\n",
        "  plt.title(\"Confusion Matrix for predicting the test dataset\")\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "gcTnyfQiDeYV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8mOdJvpE2HgZ"
      },
      "source": [
        "---\n",
        "K nearest neighbors (K-NN) (Supervised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xqcD75NW2GAO"
      },
      "outputs": [],
      "source": [
        "def KNN_algorithm(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  # Dataset is already split into train and test parts (80:20).\n",
        "\n",
        "  # Normalize / scale the data (Preprocessing)\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "\n",
        "  # ---\n",
        "  # Define some hyperparameters\n",
        "  N_NEIGHBORS = 5 # Default\n",
        "\n",
        "  # ---\n",
        "  # Lists of performance metrics for training\n",
        "  list_cv_train_time = []\n",
        "  list_cv_accuracy = []\n",
        "  list_cv_precision = []\n",
        "  list_cv_recall = []\n",
        "  list_cv_f1_score = []\n",
        "\n",
        "  # ---\n",
        "  # Stratified K-fold cross validation on the training set\n",
        "  skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "  fold = 1\n",
        "  for train_skf, val_skf in skf.split(X_train, y_train):\n",
        "    print(f\"Fold #{fold}\")\n",
        "    X_train_fold, y_train_fold = X_train[train_skf], y_train[train_skf]\n",
        "    X_val_fold, y_val_fold = X_train[val_skf], y_train[val_skf]\n",
        "\n",
        "    # Define KNN model (for cross validation)\n",
        "    model = KNeighborsClassifier(n_neighbors=N_NEIGHBORS) \n",
        "\n",
        "    # Fit model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "\n",
        "    y_pred = model.predict(X_val_fold)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_val_fold, y_pred, average='weighted')\n",
        "\n",
        "    list_cv_train_time.append(train_time)\n",
        "    list_cv_accuracy.append(accuracy)\n",
        "    list_cv_precision.append(precision)\n",
        "    list_cv_recall.append(recall)\n",
        "    list_cv_f1_score.append(f1)\n",
        "\n",
        "    print(f\"Training time: {train_time}\")\n",
        "    print(f\"Validation accuracy: {accuracy}\")\n",
        "    print(f\"Validation precision: {precision}\")\n",
        "    print(f\"Validation recall: {recall}\")\n",
        "    print(f\"Validation F1-score: {f1}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "  cv_eval_metrics = [list_cv_train_time, list_cv_accuracy,  list_cv_precision, list_cv_recall, list_cv_f1_score]\n",
        "\n",
        "  # ---\n",
        "  # Define KNN model\n",
        "  model = KNeighborsClassifier(n_neighbors=N_NEIGHBORS) \n",
        "\n",
        "  # ---\n",
        "  # Fit model to training set and evaluate the model on the test set\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"\\nResults for predicting the test dataset:\")\n",
        "  print(\"=====================================================\")\n",
        "  print(classification_report(y_test, y_pred, target_names=CR_LETTERS, digits=6))\n",
        "  print(\"=====================================================\")\n",
        "\n",
        "  # Print Confusion matrix of predicting the test set\n",
        "  render_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  return cv_eval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "knn_cv_results = KNN_algorithm(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "5vmQXBGDmu1d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lbjuxnkx8Sxm"
      },
      "source": [
        "---\n",
        "Support Vector Machine (SVM) (Supervised)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6yMMmuYO2Ftp"
      },
      "outputs": [],
      "source": [
        "def SVM_algorithm(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  # Dataset is already split into train and test parts (80:20).\n",
        "\n",
        "  # Normalize / scale the data (Preprocessing)\n",
        "  scaler = MinMaxScaler()\n",
        "  X_train = scaler.fit_transform(X_train)\n",
        "  X_test = scaler.transform(X_test)\n",
        "  \n",
        "  # ---\n",
        "  # Define some hyperparameters\n",
        "  KERNEL = 'linear' # Default is 'rbf'\n",
        "  C = 1.0 # Default\n",
        "  \n",
        "  # ---\n",
        "  # Lists of performance metrics for training\n",
        "  list_cv_train_time = []\n",
        "  list_cv_accuracy = []\n",
        "  list_cv_precision = []\n",
        "  list_cv_recall = []\n",
        "  list_cv_f1_score = []\n",
        "\n",
        "  # ---\n",
        "  # Stratified K-fold cross validation on the training set\n",
        "  skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "  fold = 1\n",
        "  for train_skf, val_skf in skf.split(X_train, y_train):\n",
        "    print(f\"Fold #{fold}\")\n",
        "    X_train_fold, y_train_fold = X_train[train_skf], y_train[train_skf]\n",
        "    X_val_fold, y_val_fold = X_train[val_skf], y_train[val_skf]\n",
        "\n",
        "    # Define SVM model (for cross validation)\n",
        "    model = SVC(kernel=KERNEL, C=C)\n",
        "\n",
        "    # Fit model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_fold, y_train_fold)\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "\n",
        "    y_pred = model.predict(X_val_fold)\n",
        "    #y_pred = np.argmax(model.predict(X_val_fold), axis=-1)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    accuracy = accuracy_score(y_val_fold, y_pred)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_val_fold, y_pred, average='weighted')\n",
        "\n",
        "    list_cv_train_time.append(train_time)\n",
        "    list_cv_accuracy.append(accuracy)\n",
        "    list_cv_precision.append(precision)\n",
        "    list_cv_recall.append(recall)\n",
        "    list_cv_f1_score.append(f1)\n",
        "\n",
        "    print(f\"Training time: {train_time}\")\n",
        "    print(f\"Validation accuracy: {accuracy}\")\n",
        "    print(f\"Validation precision: {precision}\")\n",
        "    print(f\"Validation recall: {recall}\")\n",
        "    print(f\"Validation F1-score: {f1}\")\n",
        "\n",
        "    fold += 1\n",
        "\n",
        "  cv_eval_metrics = [list_cv_train_time, list_cv_accuracy,  list_cv_precision, list_cv_recall, list_cv_f1_score]\n",
        "\n",
        "  # ---\n",
        "  # Define SVM model\n",
        "  model = SVC(kernel=KERNEL, C=C) \n",
        "\n",
        "  # ---\n",
        "  # Fit model to training set and evaluate the model on the test set\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  print(\"\\nResults for predicting the test dataset:\")\n",
        "  print(\"=====================================================\")\n",
        "  print(classification_report(y_test, y_pred, target_names=CR_LETTERS, digits=6))\n",
        "  print(\"=====================================================\")\n",
        "\n",
        "  # Print Confusion matrix of predicting the test set\n",
        "  render_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  return cv_eval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "svm_cv_results = SVM_algorithm(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "YCA4Fr_lmAU2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VIz_D3-v2HCZ"
      },
      "source": [
        "---\n",
        "Convolutional Neural Network (CNN) (Deep Learning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f39DECbv6NO5"
      },
      "outputs": [],
      "source": [
        "def CNN_algorithm(X_train, X_test, y_train, y_test):\n",
        "\n",
        "  # Dataset is already split into train and test parts (80:20).\n",
        "\n",
        "  # Normalize / scale the data (Preprocessing)\n",
        "  X_train = X_train / 255\n",
        "  X_test = X_test / 255\n",
        "\n",
        "  # ---\n",
        "  # Reshape (Preprocessing)\n",
        "  X_train = X_train.values.reshape(-1,28,28,1)\n",
        "  X_test = X_test.values.reshape(-1,28,28,1)\n",
        "\n",
        "  # ---\n",
        "  # Define some hyperparameters\n",
        "  IMAGE_SIZE = (28,28,1)\n",
        "  OUTPUT = 26 # Number of potential classes, 0-25, but 9(J) and 25(Z) are not used.\n",
        "  KERNEL = (3,3)\n",
        "  POOL_SIZE = (2,2)\n",
        "  MAX_NEURONS = 120\n",
        "  MAX_FILTERS = 64\n",
        "  LOSS_FUNCTION = 'sparse_categorical_crossentropy'\n",
        "  OPTIMIZER = 'adam'\n",
        "\n",
        "  EPOCHS = 10\n",
        "  BATCH_SIZE = 256\n",
        "\n",
        "  # ---\n",
        "  # Lists of performance metrics for training\n",
        "  list_cv_train_time = []\n",
        "  list_cv_accuracy = []\n",
        "  list_cv_precision = []\n",
        "  list_cv_recall = []\n",
        "  list_cv_f1_score = []\n",
        "\n",
        "  # ---\n",
        "  # Stratified K-fold cross validation on the training set\n",
        "  skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "  fold = 1\n",
        "  for train_skf, val_skf in skf.split(X_train, y_train):\n",
        "    print(f\"Fold #{fold}\")\n",
        "    X_train_fold, y_train_fold = X_train[train_skf], y_train[train_skf]\n",
        "    X_val_fold, y_val_fold = X_train[val_skf], y_train[val_skf]\n",
        "\n",
        "    # Define and compile CNN model (for cross validation)\n",
        "    model = Sequential([\n",
        "      Conv2D(filters=(MAX_FILTERS/2), kernel_size=KERNEL, activation='relu', input_shape=IMAGE_SIZE),\n",
        "      MaxPooling2D(pool_size=POOL_SIZE),\n",
        "      Conv2D(filters=MAX_FILTERS, kernel_size=KERNEL, activation='relu'),\n",
        "      MaxPooling2D(pool_size=POOL_SIZE),\n",
        "      Flatten(),\n",
        "      Dense(units=MAX_NEURONS, activation='relu'),\n",
        "      Dense(units=(MAX_NEURONS/2), activation='relu'),\n",
        "      Dense(units=26, activation='softmax')\n",
        "    ])\n",
        "    model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=['accuracy'])\n",
        "\n",
        "    # Fit model\n",
        "    start_time = time.time()\n",
        "    model.fit(X_train_fold, y_train_fold, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
        "    end_time = time.time()\n",
        "    train_time = end_time - start_time\n",
        "\n",
        "    y_pred = np.argmax(model.predict(X_val_fold), axis=-1)\n",
        "\n",
        "    # Calculate performance metrics\n",
        "    _, accuracy = model.evaluate(X_train_fold, y_train_fold, verbose=0)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(y_val_fold, y_pred, average='weighted')\n",
        "\n",
        "    list_cv_train_time.append(train_time)\n",
        "    list_cv_accuracy.append(accuracy)\n",
        "    list_cv_precision.append(precision)\n",
        "    list_cv_recall.append(recall)\n",
        "    list_cv_f1_score.append(f1)\n",
        "\n",
        "    print(f\"Training time: {train_time}\")\n",
        "    print(f\"Validation accuracy: {accuracy}\")\n",
        "    print(f\"Validation precision: {precision}\")\n",
        "    print(f\"Validation recall: {recall}\")\n",
        "    print(f\"Validation F1-score: {f1}\")\n",
        "    \n",
        "    fold += 1\n",
        "\n",
        "  cv_eval_metrics = [list_cv_train_time, list_cv_accuracy,  list_cv_precision, list_cv_recall, list_cv_f1_score]\n",
        "\n",
        "  # Define and compile CNN model\n",
        "  model = Sequential([\n",
        "    Conv2D(filters=(MAX_FILTERS/2), kernel_size=KERNEL, activation='relu', input_shape=IMAGE_SIZE),\n",
        "    MaxPooling2D(pool_size=POOL_SIZE),\n",
        "    Conv2D(filters=MAX_FILTERS, kernel_size=KERNEL, activation='relu'),\n",
        "    MaxPooling2D(pool_size=POOL_SIZE),\n",
        "    Flatten(),\n",
        "    Dense(units=MAX_NEURONS, activation='relu'),\n",
        "    Dense(units=(MAX_NEURONS/2), activation='relu'),\n",
        "    Dense(units=26, activation='softmax')\n",
        "  ])\n",
        "  model.compile(optimizer=OPTIMIZER, loss=LOSS_FUNCTION, metrics=['accuracy'])\n",
        "\n",
        "  model.summary()\n",
        "\n",
        "  # Fit model to training set and evaluate the model on the test set\n",
        "  model.fit(X_train, y_train, batch_size=BATCH_SIZE, epochs=EPOCHS, verbose=1)\n",
        "  y_pred = np.argmax(model.predict(X_test), axis=1)\n",
        "  print(\"\\nResults for predicting the test dataset:\")\n",
        "  print(\"=====================================================\")\n",
        "  print(classification_report(y_test, y_pred, target_names=CR_LETTERS, digits=6))\n",
        "  print(\"=====================================================\")\n",
        "\n",
        "  # Print Confusion matrix of predicting the test set\n",
        "  render_confusion_matrix(y_test, y_pred)\n",
        "\n",
        "  return cv_eval_metrics"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cnn_cv_results = CNN_algorithm(X_train, X_test, y_train, y_test)"
      ],
      "metadata": {
        "id": "XPR9KDXXF_ps"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cv_tabulate(cv_results):\n",
        "  HEADER = [\"Fold\", \"K-NN\", \"SVM\", \"CNN\"]\n",
        "\n",
        "  cv_knn = cv_results[0]\n",
        "  cv_svm = cv_results[1]\n",
        "  cv_cnn = cv_results[2]\n",
        "\n",
        "  dict_data={HEADER[1]:cv_knn, HEADER[2]:cv_svm, HEADER[3]:cv_cnn}\n",
        "  df_data=pd.DataFrame(dict_data)\n",
        "\n",
        "  df_data.index = np.arange(1, len(df_data) + 1)\n",
        "\n",
        "  df_data[HEADER[0]]=df_data.index\n",
        "  col_fold = df_data.pop(HEADER[0])\n",
        "  df_data.insert(0, HEADER[0], col_fold)\n",
        "\n",
        "\n",
        "  min_knn = min(cv_knn)\n",
        "  min_svm = min(cv_svm)\n",
        "  min_cnn = min(cv_cnn)\n",
        "\n",
        "  max_knn = max(cv_knn)\n",
        "  max_svm = max(cv_svm)\n",
        "  max_cnn = max(cv_cnn)\n",
        "\n",
        "  avg_knn = sum(cv_knn)/len(cv_knn)\n",
        "  avg_svm = sum(cv_svm)/len(cv_svm)\n",
        "  avg_cnn = sum(cv_cnn)/len(cv_cnn)\n",
        "\n",
        "  stdev_knn = df_data[HEADER[1]].std()\n",
        "  stdev_svm = df_data[HEADER[2]].std()\n",
        "  stdev_cnn = df_data[HEADER[3]].std()\n",
        "\n",
        "  df_avg_and_stdev = pd.DataFrame([\n",
        "      ['-', '-', '-', '-'],\n",
        "      ['min', min_knn, min_svm, min_cnn],\n",
        "      ['max', max_knn, max_svm, max_cnn],\n",
        "      ['-', '-', '-', '-'],\n",
        "      ['avg', avg_knn, avg_svm, avg_cnn],\n",
        "      ['stdev', stdev_knn, stdev_svm, stdev_cnn]],\n",
        "      columns=HEADER)\n",
        "\n",
        "  df_result = pd.concat([df_data, df_avg_and_stdev])\n",
        "\n",
        "  print(tabulate(df_result, headers=HEADER, showindex=False, tablefmt=\"rst\"))"
      ],
      "metadata": {
        "id": "20tf9JV8VtUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def Friedman_and_Nemenyi_tests(cv_list, highest_is_best):\n",
        "  cv_knn = cv_list[0]\n",
        "  cv_svm = cv_list[1]\n",
        "  cv_cnn = cv_list[2]\n",
        "\n",
        "  ALPHA = 0.05\n",
        "\n",
        "  # Friedman test\n",
        "  statistic, pvalue = friedmanchisquare(cv_knn, cv_svm, cv_cnn)\n",
        "  print(f\"\\nFriedman statistic (ratio): {statistic}\")\n",
        "  print(f\"P-value: {pvalue}\")\n",
        "  print(f\"Alpha: {ALPHA}\")\n",
        "\n",
        "  if pvalue < ALPHA:\n",
        "    \n",
        "    # ---\n",
        "    # Nemenyi post-hoc test\n",
        "    print(\"\\nThe p-value is less than alpha (significance level).\")\n",
        "    print(\"The difference between some of the averages is statistically significant.\")\n",
        "    print(\"The null hypothesis (H0) is rejected!\")\n",
        "    df_nemenyi = posthoc_nemenyi_friedman(np.array([cv_knn, cv_svm, cv_cnn]).T)\n",
        "    print(\"\")\n",
        "    print(posthoc_nemenyi_friedman(np.array([cv_knn, cv_svm, cv_cnn]).T))\n",
        "    print(\"\")\n",
        "\n",
        "    # ---\n",
        "    # P-values after pair-wise comparisons\n",
        "    p_knn_svm = df_nemenyi[0].iloc[1]\n",
        "    p_knn_cnn = df_nemenyi[0].iloc[2]\n",
        "    p_svm_cnn = df_nemenyi[1].iloc[2]\n",
        "\n",
        "    if highest_is_best == True:\n",
        "      if p_knn_svm < ALPHA:\n",
        "        print(\"The algorithm SVM performs significantly better than K-NN!\")\n",
        "\n",
        "      if p_knn_cnn < ALPHA:\n",
        "        print(\"The algorithm CNN performs significantly better than K-NN!\")\n",
        "\n",
        "      if p_svm_cnn < ALPHA:\n",
        "        print(\"The algorithm CNN performs significantly better than SVM!\")\n",
        "\n",
        "    else: # highest_is_best == False\n",
        "      if p_knn_svm < ALPHA:\n",
        "        print(\"The algorithm K-NN performs significantly better than SVM!\")\n",
        "\n",
        "      if p_knn_cnn < ALPHA:\n",
        "        print(\"The algorithm K-NN performs significantly better than CNN!\")\n",
        "\n",
        "      if p_svm_cnn < ALPHA:\n",
        "        print(\"The algorithm SVM performs significantly better than CNN!\")\n",
        "\n",
        "  else:\n",
        "    print(\"\\nThe p-value is greater than alpha (significance level).\")\n",
        "    print(\"The difference between the averages are NOT statistically signifiant.\")"
      ],
      "metadata": {
        "id": "QUFR4Tj3bcxx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "Cross-validation followed by Friedman and Nemenyi tests for each performance metric:"
      ],
      "metadata": {
        "id": "45Re8_A8iWb4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training time\n",
        "training_time_knn = knn_cv_results[0]\n",
        "training_time_svm = svm_cv_results[0]\n",
        "training_time_cnn = cnn_cv_results[0]\n",
        "cv_training_time = [training_time_knn, training_time_svm, training_time_cnn]\n",
        "\n",
        "print(\"Cross-validation results of computational performance in terms of training time:\")\n",
        "cv_tabulate(cv_training_time)\n",
        "\n",
        "Friedman_and_Nemenyi_tests(cv_training_time, False)"
      ],
      "metadata": {
        "id": "RBbXlbVohGpa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Accuracy score\n",
        "accuracy_knn = knn_cv_results[1]\n",
        "accuracy_svm = svm_cv_results[1]\n",
        "accuracy_cnn = cnn_cv_results[1]\n",
        "cv_accuracy = [accuracy_knn, accuracy_svm, accuracy_cnn]\n",
        "\n",
        "print(\"Cross-validation results of predictive performance based on accuracy:\")\n",
        "cv_tabulate(cv_accuracy)\n",
        "\n",
        "Friedman_and_Nemenyi_tests(cv_accuracy, True)"
      ],
      "metadata": {
        "id": "a-VXzceIfHqP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Precision score\n",
        "precision_knn = knn_cv_results[2]\n",
        "precision_svm = svm_cv_results[2]\n",
        "precision_cnn = cnn_cv_results[2]\n",
        "cv_precision = [precision_knn, precision_svm, precision_cnn]\n",
        "\n",
        "print(\"Cross-validation results of predictive performance based on precision:\")\n",
        "cv_tabulate(cv_precision)\n",
        "\n",
        "\n",
        "Friedman_and_Nemenyi_tests(cv_precision, True)"
      ],
      "metadata": {
        "id": "Sh59qGeFfHn6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Recall score\n",
        "recall_knn = knn_cv_results[3]\n",
        "recall_svm = svm_cv_results[3]\n",
        "recall_cnn = cnn_cv_results[3]\n",
        "cv_recall = [recall_knn, recall_svm, recall_cnn]\n",
        "print(\"Cross-validation results of predictive performance based on recall:\")\n",
        "cv_tabulate(cv_recall)\n",
        "\n",
        "Friedman_and_Nemenyi_tests(cv_recall, True)"
      ],
      "metadata": {
        "id": "SH2oF4XofHlM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1-score / F-Measure\n",
        "f1_score_knn = knn_cv_results[4]\n",
        "f1_score_svm = svm_cv_results[4]\n",
        "f1_score_cnn = cnn_cv_results[4]\n",
        "cv_f1_score = [f1_score_knn, f1_score_svm, f1_score_cnn]\n",
        "print(\"Cross-validation results of predictive performance based on F1-score / F-measure:\")\n",
        "cv_tabulate(cv_f1_score)\n",
        "\n",
        "Friedman_and_Nemenyi_tests(cv_f1_score, True)"
      ],
      "metadata": {
        "id": "LGuekiwIfHbf"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "premium"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}